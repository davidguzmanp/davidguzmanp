# David Guzman Piedrahita
ğŸŒ ZÃ¼rich, Switzerland | ğŸ“ MSc in AI @ University of ZÃ¼rich | ğŸ’¼ LLM Engineer @ UZH Institute for Computational Linguistics

## About Me
Highly driven ML engineer with a passion for pushing the boundaries of AI. Currently diving deep into LLMs, NLP, and multi-agent systems. Always eager to learn and contribute to cutting-edge research and development.

ğŸ¯ **Are you looking for a versatile AI engineer who can:**
- Fine-tune and optimize large language models?
- Develop innovative NLP solutions?
- Bridge the gap between research and practical applications?

Then I'm the right person for your role! With experience in academic research and industry projects, I bring a unique blend of theoretical knowledge and hands-on skills to tackle complex AI challenges.

## ğŸš€ Current Focus
- Fine-tuning large-scale LLMs on Cerebras chips
- Exploring multi-agent simulations with LLMs
- Developing novel approaches in adversarial NLP

## ğŸ›  Tech Stack
Python | PyTorch | TensorFlow | SQL | Git | Hugging Face Transformers | NLP | Time Series Forecasting

## ğŸ” Recent Projects
- [BeamAttack](https://github.com/davidguzmanp/BeamAttack): SOTA adversarial attacks against NLP classifiers (CLEF2024 Competition Submission)
  - Developed a novel algorithm that significantly outperforms traditional greedy search methods in generating adversarial text
  - Achieved up to 2.8x and 3.3x improvement in success rates against BiLSTM and BERT models, respectively
  - Implemented adaptive beam search techniques to balance attack effectiveness and computational efficiency

- [Distilling Chain-of-Thought Reasoning](https://github.com/davidguzmanp/chain-of-thought-distillation): Enhancing task-specific workflows
  - Created an innovative graph-to-text pipeline by breaking down complex tasks into manageable stages
  - Implemented knowledge distillation to incorporate chain-of-thought reasoning into smaller, more efficient models
  - Leveraged synthetic data from LLMs to improve performance in low-resource settings
  - Achieved a 9.22% increase in BLEU score and 12.31% improvement in TER

- [Metaphors Unveiled](https://github.com/davidguzmanp/metaphor-interpretation): Exploring LLMs for figurative text interpretation
  - Evaluated various LLMs (FLANT5 large, Mistral, Phi1.5B) on their ability to interpret and simplify figurative language
  - Combined sequence-to-sequence fine-tuning with advanced prompt engineering techniques
  - Boosted accuracy from 61.5% to 71.4% through optimized prompt design
  - Conducted human evaluations to provide insights beyond automated metrics

## ğŸ“« Connect with Me
[LinkedIn](https://linkedin.com/in/davidguzman1120) 

*Open to full-time opportunities in ML/AI research and development roles! If you're seeking a dedicated AI engineer who can drive innovation and deliver results, let's connect!*
<!--
**davidguzmanp/davidguzmanp** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ğŸ”­ Iâ€™m currently working on ...
- ğŸŒ± Iâ€™m currently learning ...
- ğŸ‘¯ Iâ€™m looking to collaborate on ...
- ğŸ¤” Iâ€™m looking for help with ...
- ğŸ’¬ Ask me about ...
- ğŸ“« How to reach me: ...
- ğŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->
